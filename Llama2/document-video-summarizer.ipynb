{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:21:17.667637Z","iopub.status.busy":"2024-08-27T15:21:17.667245Z","iopub.status.idle":"2024-08-27T15:21:54.802686Z","shell.execute_reply":"2024-08-27T15:21:54.801593Z","shell.execute_reply.started":"2024-08-27T15:21:17.667597Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\n","Collecting langchain\n","  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n","Collecting textract\n","  Downloading textract-1.6.5-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.3.0,>=0.2.32 (from langchain)\n","  Downloading langchain_core-0.2.35-py3-none-any.whl.metadata (6.2 kB)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n","  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.105-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\n","Collecting argcomplete~=1.10.0 (from textract)\n","  Downloading argcomplete-1.10.3-py2.py3-none-any.whl.metadata (16 kB)\n","Collecting beautifulsoup4~=4.8.0 (from textract)\n","  Downloading beautifulsoup4-4.8.2-py3-none-any.whl.metadata (4.1 kB)\n","Collecting chardet==3.* (from textract)\n","  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n","Collecting docx2txt~=0.8 (from textract)\n","  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting extract-msg<=0.29.* (from textract)\n","  Downloading extract_msg-0.28.7-py2.py3-none-any.whl.metadata (7.8 kB)\n","Collecting pdfminer.six==20191110 (from textract)\n","  Downloading pdfminer.six-20191110-py2.py3-none-any.whl.metadata (1.7 kB)\n","Collecting python-pptx~=0.6.18 (from textract)\n","  Downloading python_pptx-0.6.23-py3-none-any.whl.metadata (18 kB)\n","Collecting six~=1.12.0 (from textract)\n","  Downloading six-1.12.0-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting SpeechRecognition~=3.8.1 (from textract)\n","  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl.metadata (28 kB)\n","Collecting xlrd~=1.2.0 (from textract)\n","  Downloading xlrd-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (3.20.0)\n","Requirement already satisfied: sortedcontainers in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: soupsieve>=1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4~=4.8.0->textract) (2.5)\n","Collecting imapclient==2.1.0 (from extract-msg<=0.29.*->textract)\n","  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: olefile>=0.46 in /opt/conda/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (0.47)\n","Collecting tzlocal>=2.1 (from extract-msg<=0.29.*->textract)\n","  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n","Collecting compressed-rtf>=1.0.6 (from extract-msg<=0.29.*->textract)\n","  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting ebcdic>=1.1.1 (from extract-msg<=0.29.*->textract)\n","  Downloading ebcdic-1.1.1-py2.py3-none-any.whl.metadata (8.9 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n","Collecting packaging>=20.0 (from transformers)\n","  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n","Requirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (5.3.0)\n","Requirement already satisfied: Pillow>=3.3.2 in /opt/conda/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (9.5.0)\n","Collecting XlsxWriter>=0.5.7 (from python-pptx~=0.6.18->textract)\n","  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (2.4)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n","Downloading langchain-0.2.14-py3-none-any.whl (997 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading textract-1.6.5-py3-none-any.whl (23 kB)\n","Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n","Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.2.35-py3-none-any.whl (394 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.105-py3-none-any.whl (150 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.5/150.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n","Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\n","Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf\n","  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=2d3b6fb0c528f3d6fda8d5085a6c7195b7f0bfbc23571da271b171dfd73ae044\n","  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n","  Building wheel for compressed-rtf (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6185 sha256=dd73d4ada5958428bd22f70dd0636b2ec912e83f15cb1ba0186d9b53683f2ccc\n","  Stored in directory: /root/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\n","Successfully built docx2txt compressed-rtf\n","\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: SpeechRecognition, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, tzlocal, six, packaging, beautifulsoup4, python-pptx, pdfminer.six, imapclient, langsmith, extract-msg, textract, langchain-core, langchain-text-splitters, langchain\n","  Attempting uninstall: six\n","    Found existing installation: six 1.16.0\n","    Uninstalling six-1.16.0:\n","      Successfully uninstalled six-1.16.0\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.12.3\n","    Uninstalling beautifulsoup4-4.12.3:\n","      Successfully uninstalled beautifulsoup4-4.12.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.8.2 requires cubinlinker, which is not installed.\n","cudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.8.2 requires ptxcompiler, which is not installed.\n","cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\n","pyarabic 0.6.15 requires six>=1.14.0, but you have six 1.12.0 which is incompatible.\n","cudf 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n","distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","jupyterlab 4.2.4 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","libpysal 4.9.2 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.2 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","opencensus 0.11.4 requires six~=1.16, but you have six 1.12.0 which is incompatible.\n","osmnx 1.9.4 requires shapely<2.1,>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","pointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\n","spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","textblob 0.18.0.post0 requires nltk>=3.8, but you have nltk 3.2.4 which is incompatible.\n","ydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed SpeechRecognition-3.8.1 XlsxWriter-3.2.0 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 langchain-0.2.14 langchain-core-0.2.35 langchain-text-splitters-0.2.2 langsmith-0.1.105 packaging-24.1 pdfminer.six-20191110 python-pptx-0.6.23 six-1.12.0 textract-1.6.5 tzlocal-5.2 xlrd-1.2.0\n"]}],"source":["!pip install transformers langchain textract "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:21:54.804978Z","iopub.status.busy":"2024-08-27T15:21:54.804652Z","iopub.status.idle":"2024-08-27T15:23:03.246061Z","shell.execute_reply":"2024-08-27T15:23:03.244939Z","shell.execute_reply.started":"2024-08-27T15:21:54.804944Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.14)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.35)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.105)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (2.4)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n","\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\n","Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n","Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n","\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mCollecting langchain_community\n","  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n","Requirement already satisfied: langchain<0.3.0,>=0.2.13 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.14)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.35)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.105)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.4.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (2.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.0)\n","Downloading langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: langchain_community\n","Successfully installed langchain_community-0.2.12\n"]}],"source":["!pip install transformers\n","!pip install langchain\n","!pip install torch\n","!pip install tensorflow\n","!pip install langchain_community"]},{"cell_type":"markdown","metadata":{},"source":["# Video to Text Transcribe"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:23:03.248153Z","iopub.status.busy":"2024-08-27T15:23:03.247756Z","iopub.status.idle":"2024-08-27T15:23:37.782487Z","shell.execute_reply":"2024-08-27T15:23:37.781517Z","shell.execute_reply.started":"2024-08-27T15:23:03.248109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install git+https://github.com/openai/whisper.git -q"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:23:37.785425Z","iopub.status.busy":"2024-08-27T15:23:37.785091Z","iopub.status.idle":"2024-08-27T15:23:55.477709Z","shell.execute_reply":"2024-08-27T15:23:55.476580Z","shell.execute_reply.started":"2024-08-27T15:23:37.785391Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ndpfzbpe\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ndpfzbpe\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=c17a676995e00c5db6be00abb37f430ef070668a1fde719c511ec06f4178f2db\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0j6m9o5b/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n","Successfully built openai-whisper\n","Installing collected packages: openai-whisper\n","  Attempting uninstall: openai-whisper\n","    Found existing installation: openai-whisper 20231117\n","    Uninstalling openai-whisper-20231117:\n","      Successfully uninstalled openai-whisper-20231117\n","Successfully installed openai-whisper-20231117\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:23:55.479716Z","iopub.status.busy":"2024-08-27T15:23:55.479296Z","iopub.status.idle":"2024-08-27T15:24:10.727170Z","shell.execute_reply":"2024-08-27T15:24:10.726040Z","shell.execute_reply.started":"2024-08-27T15:23:55.479670Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting setuptools-rust\n","  Downloading setuptools_rust-1.10.1-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: setuptools>=62.4 in /opt/conda/lib/python3.10/site-packages (from setuptools-rust) (70.0.0)\n","Collecting semantic-version<3,>=2.8.2 (from setuptools-rust)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Downloading setuptools_rust-1.10.1-py3-none-any.whl (26 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: semantic-version, setuptools-rust\n","Successfully installed semantic-version-2.10.0 setuptools-rust-1.10.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install setuptools-rust"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:24:10.728965Z","iopub.status.busy":"2024-08-27T15:24:10.728633Z","iopub.status.idle":"2024-08-27T15:24:17.260653Z","shell.execute_reply":"2024-08-27T15:24:17.259729Z","shell.execute_reply.started":"2024-08-27T15:24:10.728931Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 192MiB/s]\n","/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(fp, map_location=device)\n"]}],"source":["import whisper\n","\n","model = whisper.load_model(\"base\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:24:17.263259Z","iopub.status.busy":"2024-08-27T15:24:17.262287Z","iopub.status.idle":"2024-08-27T15:24:17.270584Z","shell.execute_reply":"2024-08-27T15:24:17.269596Z","shell.execute_reply.started":"2024-08-27T15:24:17.263194Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model.device"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:24:17.272554Z","iopub.status.busy":"2024-08-27T15:24:17.272157Z","iopub.status.idle":"2024-08-27T15:24:33.905546Z","shell.execute_reply":"2024-08-27T15:24:33.904427Z","shell.execute_reply.started":"2024-08-27T15:24:17.272495Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting yt_dlp\n","  Downloading yt_dlp-2024.8.6-py3-none-any.whl.metadata (170 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.1/170.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: brotli in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (1.1.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (2024.7.4)\n","Collecting mutagen (from yt_dlp)\n","  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n","Collecting pycryptodomex (from yt_dlp)\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Requirement already satisfied: requests<3,>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (2.32.3)\n","Requirement already satisfied: urllib3<3,>=1.26.17 in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (1.26.18)\n","Requirement already satisfied: websockets>=12.0 in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.32.2->yt_dlp) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.32.2->yt_dlp) (3.7)\n","Downloading yt_dlp-2024.8.6-py3-none-any.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: pycryptodomex, mutagen, yt_dlp\n","Successfully installed mutagen-1.47.0 pycryptodomex-3.20.0 yt_dlp-2024.8.6\n"]}],"source":["!pip install yt_dlp "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:24:33.907477Z","iopub.status.busy":"2024-08-27T15:24:33.907048Z","iopub.status.idle":"2024-08-27T15:24:34.535048Z","shell.execute_reply":"2024-08-27T15:24:34.534007Z","shell.execute_reply.started":"2024-08-27T15:24:33.907411Z"},"trusted":true},"outputs":[],"source":["import yt_dlp\n","\n","def extract_audio(url):\n","    \"\"\"Extracts audio from a YouTube video using yt-dlp.\"\"\"\n","    ydl_opts = {\n","        'format': 'bestaudio/best',\n","        'postprocessors': [{\n","            'key': 'FFmpegExtractAudio',\n","            'preferredcodec': 'mp3',\n","            'preferredquality': '192',\n","        }],\n","        'outtmpl': 'output.%(ext)s'\n","    }\n","\n","    try:\n","        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n","            info_dict = ydl.extract_info(url, download=True)\n","            audio_file = ydl.prepare_filename(info_dict)\n","            audio_file = audio_file.replace('.webm', '.mp3')  # Ensure correct file extension\n","            return audio_file\n","    except Exception as e:\n","        print(f\"Error extracting audio: {e}\")\n","        return None"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:24:34.539168Z","iopub.status.busy":"2024-08-27T15:24:34.538857Z","iopub.status.idle":"2024-08-27T15:24:58.179703Z","shell.execute_reply":"2024-08-27T15:24:58.178743Z","shell.execute_reply.started":"2024-08-27T15:24:34.539135Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[youtube] Extracting URL: https://www.youtube.com/watch?v=VO9q66JEdVk\n","[youtube] VO9q66JEdVk: Downloading webpage\n","[youtube] VO9q66JEdVk: Downloading ios player API JSON\n","[youtube] VO9q66JEdVk: Downloading web creator player API JSON\n","[youtube] VO9q66JEdVk: Downloading player 19828c26\n","[youtube] VO9q66JEdVk: Downloading m3u8 information\n","[info] VO9q66JEdVk: Downloading 1 format(s): 251\n","[download] Destination: output.webm\n","[download] 100% of    5.81MiB in 00:00:00 at 12.92MiB/s  \n","[ExtractAudio] Destination: output.mp3\n","Deleting original file output.webm (pass -k to keep)\n"]},{"data":{"text/plain":["'output.mp3'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["url = \"https://www.youtube.com/watch?v=VO9q66JEdVk\"\n","extract_audio(url)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:24:58.181125Z","iopub.status.busy":"2024-08-27T15:24:58.180815Z","iopub.status.idle":"2024-08-27T15:24:58.186438Z","shell.execute_reply":"2024-08-27T15:24:58.185551Z","shell.execute_reply.started":"2024-08-27T15:24:58.181092Z"},"trusted":true},"outputs":[],"source":["def transcribe_audio(file_path):\n","    \"\"\"Transcribes audio to text using the Whisper model.\"\"\"\n","    try:\n","        model = whisper.load_model('base')\n","        result = model.transcribe(file_path)\n","        return result['text']\n","    except Exception as e:\n","        print(f\"Error transcribing audio: {e}\")\n","        return None\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:24:58.187852Z","iopub.status.busy":"2024-08-27T15:24:58.187508Z","iopub.status.idle":"2024-08-27T15:25:19.504304Z","shell.execute_reply":"2024-08-27T15:25:19.503265Z","shell.execute_reply.started":"2024-08-27T15:24:58.187817Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(fp, map_location=device)\n"]}],"source":["text = transcribe_audio(\"/kaggle/working/output.mp3\")"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-27T15:25:19.506253Z","iopub.status.busy":"2024-08-27T15:25:19.505942Z","iopub.status.idle":"2024-08-27T15:25:19.512504Z","shell.execute_reply":"2024-08-27T15:25:19.511493Z","shell.execute_reply.started":"2024-08-27T15:25:19.506221Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["\" Hi everyone, I'm Monar Aganti. Today I'm going to introduce you to a text and video summarization app. So in this video, I'll walk you through the app's features, architecture, typical use cases and also potential upgrades. So let's get started. First, let's talk about what this presentation will cover. Will outline our text and video summarization app, explore its architecture, go through some typical use cases and discuss potential future upgrades. And our goal is to show you how this innovative solution can make your life easier and more productive. Now let's talk about the overview of the app. Our app helps users putly grasp the events of documents, videos and articles. So it uses cutting edge technology to generate concise summaries and also highlighting key information for efficient learning or information retrieval. The key features are of our app, include the ability to summarize various text formats like documents, blog posts and video transcripts. Additionally, the app also monitors YouTube channels and automatically generates summaries for newly uploaded videos, which are the delivery to users through question notifications. Now let's walk through the user interface of our app. As you can see, there are four slides presented here starting with slide one. We have the sign up screen. So to start with the app, you need to sign up by entering your email and password. But if you already have an account and login direction and in the second slide, login by using your email and password directly. In the third slide, we have the main menu of the app, which is text and video summarization buttons. So let's say we see the text input screen. Now take an example paragraph about pollution and you type that into input box and hit send. And you will get a summarized text. As for a video, you can simply paste the URL by IC and the app will provide a concise summary of the video content. So that's the user interface of our app. Now let's talk about the architecture diagram of our app. As you can see, the diagram shows the flow chart of data and process in the app, which starts from user input and end and with delivery of some ways to use it. So here's a detailed breakdown of each component and how they interact. It starts with user input. The user begins by providing content to the app. So this could be in the form of text images of videos. And the apps suddenly interface, which is flutter allows user to easily upload or keep their content. Then comes the flood up front end. So if the user provides text or document input, then the app immediately sends this data to the summarization engine via an apr request. And as for video URLs, the app uses the YouTube API to fetch videos transcript. So the app continuously monitors last specified YouTube channels for new videos. So when a new videos uploaded, the app detects it and fetches the relevant details and transcripts using YouTube API. So once the content is ready, the app sends an apr request to the summarization engine, which is llama to. So llama to receives that the text or video transcript using advanced natural language, courses and techniques. It analyzes the content and extracts key points to generate a concise summary. So this summarization engine produces summary that highlights the most important information from the input content. Now let's talk about the summary handling. The generated summary is sent back to the flutter front end. The app displays the summary in a user friendly format, which makes it easier for the user to read and understand. But also the summary is also sent to fire this for storage, because this allows the app to keep a record of all the summaries generated for the user. And as for the flutter back end, the fire base securely store the summaries and also the user data like they emails and etc. So this ensures that the users can action their summaries at any time and that they de-tie protected. And as for the push notifications, fire with cloud messaging sends push notifications to the user device, which keeps users informed about new summaries without needing to open the app. Now let's talk in detail about the user notification when you enter a YouTube URL into the app for summarization. It stores the URL. Then the app follows the YouTube channel related to that URL. So whenever new videos are uploaded to that channel, the app makes a new summary and then the user receives a push notification. And this notification provides a quick alert that new content is available. Now if you want to access that summary, you can directly open the app to read that summary. This ensures that they see updated with minimum of 40. So this is the complete architecture diagram of our app. Now let's talk about physical use cases of our summarization app. There are many uses for this app, but let's discuss a few typical cases. Let's start with exam preparation. The students can easily upload their text materials like study materials. Let's lecture no, also text tricks. Then our app generates summaries to help them review quickly, which is useful for exams. This way they can study efficiency and also retain more information for their exams. As for the interview highlights, especially for jobs you see us. The app is a game changer by inputting links to interviews or documentaries. Users can extract and summarize key insights. This provides a valuable resource for preparing for interviews or conductive research, which makes the job search a bit easier. Now staying updated is crucial and our app helps with that. Users can monitor their favorite YouTube channels like for new content. And the app automatically summarizes new uploads and sends notifications, which enables the users to keep learning and stay informed about the latest terms. As for the potential updates, we'll see what else can we add to the app. In hands and AI models, we are looking to integrate advanced summarization models, which enhance the accuracy and relevance of our summaries. Which will deliver a more new sense done informative experience for our users. And also to broaden our appeal, we can expand the app to support multiple languages. This will make it accessible to users around the group reaching a much wider audience. And to improve the performance of the app, we can implement feedback mechanisms here. The users can refine the summaries to better fit their needs. Like this will personalize their experience and also significantly enhance their overall satisfaction. As for the offline mode, it convenience significantly. So we are we can enable the offline access to download summaries. This will allow users to access the material anytime, even without an internet connection. So this is the overview of the text summarization app so far. I hope it helps you and thank you for watching.\""]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["text"]},{"cell_type":"markdown","metadata":{},"source":["# Document Summarization Using Bart"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:25:19.513982Z","iopub.status.busy":"2024-08-27T15:25:19.513645Z","iopub.status.idle":"2024-08-27T15:25:21.714040Z","shell.execute_reply":"2024-08-27T15:25:21.713211Z","shell.execute_reply.started":"2024-08-27T15:25:19.513949Z"},"trusted":true},"outputs":[],"source":["from transformers import BartForConditionalGeneration, BartTokenizer\n","from langchain.text_splitter import RecursiveCharacterTextSplitter"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:25:21.715880Z","iopub.status.busy":"2024-08-27T15:25:21.715310Z","iopub.status.idle":"2024-08-27T15:25:30.049411Z","shell.execute_reply":"2024-08-27T15:25:30.048465Z","shell.execute_reply.started":"2024-08-27T15:25:21.715835Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b738fada1d47470cbff41d8434070c6c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa779a83b564499498e100c855fcda70","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c16dde91761b4e729e30b76170693ed8","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b375e694b7f0449cbf4fdfa2bc272209","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fe4e4c1605841039b8577d5524d86bb","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8817625e6184031b2ac7b54c88531d3","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["model = BartForConditionalGeneration.from_pretrained(\n","        'facebook/bart-large-cnn')\n","\n","tokenizer = BartTokenizer.from_pretrained(\n","            'facebook/bart-large-cnn')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:25:30.051086Z","iopub.status.busy":"2024-08-27T15:25:30.050768Z","iopub.status.idle":"2024-08-27T15:25:30.058231Z","shell.execute_reply":"2024-08-27T15:25:30.057324Z","shell.execute_reply.started":"2024-08-27T15:25:30.051053Z"},"trusted":true},"outputs":[],"source":["import textract\n","\n","def extract_text(file_path):\n","    try:\n","        text = textract.process(file_path)\n","        return text.decode('utf-8')\n","    except Exception as e:\n","        print(f\"An error occurred while processing {file_path}: {e}\")\n","        return None"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:25:30.059968Z","iopub.status.busy":"2024-08-27T15:25:30.059520Z","iopub.status.idle":"2024-08-27T15:25:30.072963Z","shell.execute_reply":"2024-08-27T15:25:30.071989Z","shell.execute_reply.started":"2024-08-27T15:25:30.059925Z"},"trusted":true},"outputs":[],"source":["def summarize(text, maxSummarylength):\n","    # Encode the text and summarize\n","    inputs = tokenizer.encode(\"summarize: \" +\n","                              text,\n","                              return_tensors = \"pt\",\n","                              max_length = 1024, truncation=True)\n","\n","    summary_ids = model.generate(inputs,\n","                                 max_length = maxSummarylength,\n","                                 min_length = int(maxSummarylength/5),\n","                                 length_penalty = 10.0,\n","                                 num_beams = 4,\n","                                 early_stopping = True)\n","\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens = True)\n","\n","    return summary"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-08-27T07:59:20.889287Z","iopub.status.busy":"2024-08-27T07:59:20.888871Z","iopub.status.idle":"2024-08-27T07:59:20.896844Z","shell.execute_reply":"2024-08-27T07:59:20.895851Z","shell.execute_reply.started":"2024-08-27T07:59:20.889249Z"}},"source":["def split_text_into_pieces(text, max_tokens=1024, use_sentence_boundary=False):\n","    \"\"\"\n","    Splits the text into pieces based on the max_tokens, optionally considering sentence boundaries.\n","    \n","    Parameters:\n","    text (str): The text to be split.\n","    max_tokens (int): Maximum tokens per piece.\n","    use_sentence_boundary (bool): Whether to split at sentence boundaries.\n","    \n","    Returns:\n","    List[str]: A list of text pieces.\n","    \"\"\"\n","    if use_sentence_boundary:\n","        sentences = text.split('. ')\n","        pieces = []\n","        current_piece = ''\n","        for sentence in sentences:\n","            if len(tokenizer.tokenize(current_piece + sentence)) <= max_tokens:\n","                current_piece += sentence + '. '\n","            else:\n","                pieces.append(current_piece.strip())\n","                current_piece = sentence + '. '\n","        if current_piece:\n","            pieces.append(current_piece.strip())\n","        return pieces\n","    else:\n","        return [text[i:i+max_tokens] for i in range(0, len(text), max_tokens)]"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-08-27T08:16:19.711404Z","iopub.status.busy":"2024-08-27T08:16:19.710201Z","iopub.status.idle":"2024-08-27T08:16:19.724050Z","shell.execute_reply":"2024-08-27T08:16:19.722667Z","shell.execute_reply.started":"2024-08-27T08:16:19.711318Z"}},"source":["def recursive_summarize(text, max_length=1024, recursion_level=0, detail_level=3):\n","    \"\"\"\n","    Recursive summarization function that provides a concise yet detailed summary.\n","    \n","    Parameters:\n","    text (str): The text to be summarized.\n","    max_length (int): The maximum token length for each chunk.\n","    recursion_level (int): Current recursion level (used internally for tracking depth).\n","    detail_level (int): Level of detail for the final summary. Lower values produce more detailed summaries.\n","    \n","    Returns:\n","    str: The final summary after recursive summarization.\n","    \"\"\"\n","    recursion_level += 1\n","    print(\"######### Recursion level: \", recursion_level, \"\\n\\n######### \")\n","\n","    tokens = tokenizer.tokenize(text)\n","    expected_count_of_chunks = len(tokens) / max_length\n","    max_length = int(len(tokens) / expected_count_of_chunks) + 2\n","\n","    # Break the text into pieces based on max_length, considering sentence boundaries\n","    pieces = split_text_into_pieces(text, max_tokens=max_length, use_sentence_boundary=True)\n","\n","    print(\"Number of pieces: \", len(pieces))\n","\n","    # Summarize each piece\n","    summaries = []\n","    for k, piece in enumerate(pieces):\n","        print(\"****************************************************\")\n","        print(\"Piece:\", k + 1, \" out of \", len(pieces), \"pieces\")\n","        print(piece, \"\\n\")\n","        \n","        # Adjust summary length based on detail level\n","        summary_length = int(max_length / detail_level)\n","        summary = summarize(piece, maxSummarylength=summary_length)\n","        \n","        print(\"SUMMARY: \", summary)\n","        summaries.append(summary)\n","        print(\"****************************************************\")\n","\n","    # Concatenate the summaries and tokenize again\n","    concatenated_summary = ' '.join(summaries)\n","    tokens = tokenizer.tokenize(concatenated_summary)\n","\n","    if len(tokens) > max_length:\n","        # If the concatenated summary is too long, repeat the process\n","        print(\"############# GOING RECURSIVE ##############\")\n","        return recursive_summarize(concatenated_summary,\n","                                   max_length=max_length,\n","                                   recursion_level=recursion_level,\n","                                   detail_level=detail_level)\n","    else:\n","        # Perform a final summarization if necessary\n","        final_summary = concatenated_summary\n","        if len(pieces) > 1:\n","            final_summary = summarize(concatenated_summary,\n","                                      maxSummarylength=int(max_length / detail_level * 2))\n","\n","        return final_summary\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:25:30.074420Z","iopub.status.busy":"2024-08-27T15:25:30.074129Z","iopub.status.idle":"2024-08-27T15:25:30.084963Z","shell.execute_reply":"2024-08-27T15:25:30.084167Z","shell.execute_reply.started":"2024-08-27T15:25:30.074389Z"},"trusted":true},"outputs":[],"source":["def split_text_into_pieces(text, max_tokens=1024, use_sentence_boundary=False):\n","    \"\"\"\n","    Splits the text into pieces based on the max_tokens, optionally considering sentence boundaries.\n","    \n","    Parameters:\n","    text (str): The text to be split.\n","    max_tokens (int): Maximum tokens per piece.\n","    use_sentence_boundary (bool): Whether to split at sentence boundaries.\n","    \n","    Returns:\n","    List[str]: A list of text pieces.\n","    \"\"\"\n","    if use_sentence_boundary:\n","        sentences = text.split('. ')\n","        pieces = []\n","        current_piece = ''\n","        for sentence in sentences:\n","            if len(tokenizer.tokenize(current_piece + sentence)) <= max_tokens:\n","                current_piece += sentence + '. '\n","            else:\n","                pieces.append(current_piece.strip())\n","                current_piece = sentence + '. '\n","        if current_piece:\n","            pieces.append(current_piece.strip())\n","        return pieces\n","    else:\n","        return [text[i:i+max_tokens] for i in range(0, len(text), max_tokens)]"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:25:30.086438Z","iopub.status.busy":"2024-08-27T15:25:30.086101Z","iopub.status.idle":"2024-08-27T15:25:30.100934Z","shell.execute_reply":"2024-08-27T15:25:30.100098Z","shell.execute_reply.started":"2024-08-27T15:25:30.086406Z"},"trusted":true},"outputs":[],"source":["def recursive_summarize(text, max_length=1024, recursion_level=0, detail_level=3):\n","    \"\"\"\n","    Recursive summarization function that provides a concise yet detailed summary.\n","    \n","    Parameters:\n","    text (str): The text to be summarized.\n","    max_length (int): The maximum token length for each chunk.\n","    recursion_level (int): Current recursion level (used internally for tracking depth).\n","    detail_level (int): Level of detail for the final summary. Lower values produce more detailed summaries.\n","    \n","    Returns:\n","    str: The final summary after recursive summarization.\n","    \"\"\"\n","    recursion_level += 1\n","\n","    tokens = tokenizer.tokenize(text)\n","    expected_count_of_chunks = len(tokens) / max_length\n","    max_length = int(len(tokens) / expected_count_of_chunks) + 2\n","\n","    # Break the text into pieces based on max_length, considering sentence boundaries\n","    pieces = split_text_into_pieces(text, max_tokens=max_length, use_sentence_boundary=True)\n","\n","    # Summarize each piece\n","    summaries = []\n","    for piece in pieces:\n","        # Adjust summary length based on detail level\n","        summary_length = int(max_length / detail_level)\n","        summary = summarize(piece, summary_length)\n","        summaries.append(summary)\n","\n","    # Concatenate the summaries and tokenize again\n","    concatenated_summary = ' '.join(summaries)\n","    tokens = tokenizer.tokenize(concatenated_summary)\n","\n","    if len(tokens) > max_length:\n","        # If the concatenated summary is too long, repeat the process\n","        return recursive_summarize(concatenated_summary,\n","                                   max_length=max_length,\n","                                   recursion_level=recursion_level,\n","                                   detail_level=detail_level)\n","    else:\n","        # Perform a final summarization if necessary\n","        final_summary = concatenated_summary\n","        if len(pieces) > 1:\n","            final_summary = summarize(concatenated_summary,\n","                                      maxSummarylength=int(max_length / detail_level * 2))\n","\n","        return final_summary"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:25:30.102342Z","iopub.status.busy":"2024-08-27T15:25:30.102017Z","iopub.status.idle":"2024-08-27T15:28:01.777405Z","shell.execute_reply":"2024-08-27T15:28:01.776363Z","shell.execute_reply.started":"2024-08-27T15:25:30.102306Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Concise and Detailed Summary:\n","A trigger is a stored database object that is automatically executed or fired on a DML command. A procedure is a subroutine or a subprogram in the language of the database. Triggers are used to invoke procedures by using other triggers, such as Java, Python, PHP, etc. The Data Controlling Language (DCL) helps users to retrieve, modify and delete data stored on the server. DCL commands can be used to grant or revoke user permissions and privileges as per the administrator’s needs. The DBA is the focal point for data/user interaction in an organization. The technical aspects of the DBA's job are rooted in the following areas of operation: design, development, implementation, and maintenance.\n"]}],"source":["document = extract_text(\"/kaggle/input/dbms-da/DBMS Unit 5 Tesseract.pdf\")\n","\n","if document:\n","    summary = recursive_summarize(document, max_length=1024, detail_level=3)\n","    print(\"Concise and Detailed Summary:\")\n","    print(summary)\n","else:\n","    print(\"Failed to extract text from the document.\")"]},{"cell_type":"markdown","metadata":{},"source":["# Flask Backend Using Ngrok"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:28:01.779739Z","iopub.status.busy":"2024-08-27T15:28:01.778952Z","iopub.status.idle":"2024-08-27T15:28:15.299034Z","shell.execute_reply":"2024-08-27T15:28:15.297912Z","shell.execute_reply.started":"2024-08-27T15:28:01.779682Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyngrok\n","  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting flask_ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: Flask>=0.8 in /opt/conda/lib/python3.10/site-packages (from flask_ngrok) (3.0.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from flask_ngrok) (2.32.3)\n","Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (3.0.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (8.1.7)\n","Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (1.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->flask_ngrok) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->flask_ngrok) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->flask_ngrok) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->flask_ngrok) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask>=0.8->flask_ngrok) (2.1.5)\n","Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n","Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: pyngrok, flask_ngrok\n","Successfully installed flask_ngrok-0.0.25 pyngrok-7.2.0\n"]}],"source":["!pip install pyngrok flask_ngrok"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:28:15.301058Z","iopub.status.busy":"2024-08-27T15:28:15.300634Z","iopub.status.idle":"2024-08-27T15:28:28.500052Z","shell.execute_reply":"2024-08-27T15:28:28.498889Z","shell.execute_reply.started":"2024-08-27T15:28:15.301007Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting flask_cors\n","  Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: Flask>=0.9 in /opt/conda/lib/python3.10/site-packages (from flask_cors) (3.0.3)\n","Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (3.0.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (8.1.7)\n","Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (1.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask_cors) (2.1.5)\n","Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n","\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: flask_cors\n","Successfully installed flask_cors-4.0.1\n"]}],"source":["!pip install flask_cors"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:28:28.501864Z","iopub.status.busy":"2024-08-27T15:28:28.501503Z","iopub.status.idle":"2024-08-27T15:28:30.802163Z","shell.execute_reply":"2024-08-27T15:28:30.800977Z","shell.execute_reply.started":"2024-08-27T15:28:28.501829Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \n"]}],"source":["!ngrok authtoken \"YOUR AUTHTOKEN KEY\""]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:28:30.804066Z","iopub.status.busy":"2024-08-27T15:28:30.803725Z","iopub.status.idle":"2024-08-27T15:28:31.180870Z","shell.execute_reply":"2024-08-27T15:28:31.179818Z","shell.execute_reply.started":"2024-08-27T15:28:30.804031Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["* ngrok tunnel \"NgrokTunnel: \"https://5e84-34-83-231-88.ngrok-free.app\" -> \"http://localhost:5000\"\" -> \"http://127.0.0.1:5000\"\n"]}],"source":["from pyngrok import ngrok\n","\n","# Connect to the local Flask server running on port 5000\n","public_url = ngrok.connect(addr=\"5000\")\n","print('* ngrok tunnel \"{}\" -> \"http://127.0.0.1:5000\"'.format(public_url))\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:28:31.183009Z","iopub.status.busy":"2024-08-27T15:28:31.182200Z","iopub.status.idle":"2024-08-27T15:28:32.237557Z","shell.execute_reply":"2024-08-27T15:28:32.236269Z","shell.execute_reply.started":"2024-08-27T15:28:31.182961Z"},"trusted":true},"outputs":[],"source":["%mkdir templates -p"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:28:32.240121Z","iopub.status.busy":"2024-08-27T15:28:32.239413Z","iopub.status.idle":"2024-08-27T15:28:32.248897Z","shell.execute_reply":"2024-08-27T15:28:32.247523Z","shell.execute_reply.started":"2024-08-27T15:28:32.240081Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing templates/index.html\n"]}],"source":["%%writefile templates/index.html\n","<!DOCTYPE html>\n","<html lang=\"en\">\n","<head>\n","    <meta charset=\"UTF-8\">\n","    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n","    <title>Document Summarizer</title>\n","</head>\n","<body>\n","    <h1>Document Summarizer</h1>\n","    <form action=\"/\" method=\"POST\" enctype=\"multipart/form-data\">\n","        <label for=\"file\">Upload a file:</label><br>\n","        <input type=\"file\" id=\"file\" name=\"file\"><br><br>\n","        \n","        <label for=\"youtube_url\">Or enter a YouTube URL:</label><br>\n","        <input type=\"url\" id=\"youtube_url\" name=\"youtube_url\" placeholder=\"https://www.youtube.com/watch?v=...\"><br><br>\n","\n","        <input type=\"submit\" value=\"Summarize\">\n","    </form>\n","    \n","    {% if summary_text %}\n","    <h2>Summary:</h2>\n","    <textarea id=\"summary_text\" rows=\"10\" cols=\"80\">{{ summary_text }}</textarea><br><br>\n","    <p>Generation Time: {{ generation_time }} seconds</p>\n","    {% else %}\n","    <p>No summary generated yet.</p>\n","    {% endif %}\n","</body>\n","</html>\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:39:09.841177Z","iopub.status.busy":"2024-08-27T15:39:09.840753Z","iopub.status.idle":"2024-08-27T15:39:09.857159Z","shell.execute_reply":"2024-08-27T15:39:09.856179Z","shell.execute_reply.started":"2024-08-27T15:39:09.841138Z"},"trusted":true},"outputs":[],"source":["from flask import Flask, request, jsonify\n","from flask_cors import CORS\n","import os\n","import time\n","from werkzeug.utils import secure_filename\n","from pyngrok import ngrok\n","import textract  # Make sure to import textract\n","\n","app = Flask(__name__)\n","CORS(app, resources={r\"/*\": {\"origins\": \"*\"}}, supports_credentials=True)\n","\n","# Allowed file extensions\n","ALLOWED_EXTENSIONS = {'pdf', 'docx', 'txt'}\n","\n","def allowed_file(filename):\n","    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n","\n","def get_summary(text):\n","    try:\n","        start_time = time.time()\n","        summary = recursive_summarize(text, max_length=1024, detail_level=3)\n","        end_time = time.time()\n","        generation_time = round(end_time - start_time, 2)\n","        return summary, generation_time\n","    except Exception as e:\n","        return f\"An error occurred: {str(e)}\", 0\n","\n","@app.route('/summarize', methods=['POST'])\n","def summarize_route():\n","    input_text = None\n","    youtube_url = request.form.get('youtube_url', '')\n","\n","    # Debug logs\n","    print(\"Request received\")\n","    print(f\"YouTube URL: {youtube_url}\")\n","\n","    if 'file' in request.files and request.files['file'].filename != '':\n","        file = request.files['file']\n","        if file and allowed_file(file.filename):\n","            filename = secure_filename(file.filename)\n","            file_path = os.path.join(app.root_path, filename)\n","            file.save(file_path)\n","            input_text = textract.process(file_path).decode('utf-8')\n","            os.remove(file_path)\n","            print(f\"File processed: {filename}\")\n","        else:\n","            print(\"Invalid file type or no file selected.\")\n","    elif youtube_url:\n","        audio_file = extract_audio(youtube_url)\n","        if audio_file:\n","            input_text = transcribe_audio(audio_file)\n","            os.remove(audio_file)\n","            print(\"YouTube audio processed.\")\n","        else:\n","            print(\"Failed to extract audio.\")\n","    \n","    if input_text:\n","        summary, generation_time = get_summary(input_text)\n","        return jsonify({\n","            'summary_text': summary,\n","            'generation_time': generation_time\n","        })\n","    else:\n","        return jsonify({'error': 'Failed to process input.'}), 400\n","\n","# Note: We're not running the app here"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T15:57:35.773826Z","iopub.status.busy":"2024-08-27T15:57:35.773420Z","iopub.status.idle":"2024-08-27T16:03:24.632656Z","shell.execute_reply":"2024-08-27T16:03:24.631103Z","shell.execute_reply.started":"2024-08-27T15:57:35.773788Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Running on NgrokTunnel: \"https://c873-34-83-231-88.ngrok-free.app\" -> \"http://localhost:5000\"\n","Request received\n","YouTube URL: https://www.youtube.com/watch?v=1bUy-1hGZpI\n","[youtube] Extracting URL: https://www.youtube.com/watch?v=1bUy-1hGZpI\n","[youtube] 1bUy-1hGZpI: Downloading webpage\n","[youtube] 1bUy-1hGZpI: Downloading ios player API JSON\n","[youtube] 1bUy-1hGZpI: Downloading web creator player API JSON\n","[youtube] 1bUy-1hGZpI: Downloading m3u8 information\n","[info] 1bUy-1hGZpI: Downloading 1 format(s): 251\n","[download] Destination: output.webm\n","[download] 100% of    6.19MiB in 00:00:00 at 6.78MiB/s   \n","[ExtractAudio] Destination: output.mp3\n","Deleting original file output.webm (pass -k to keep)\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(fp, map_location=device)\n"]},{"name":"stdout","output_type":"stream","text":["YouTube audio processed.\n"]}],"source":["# Run this in a separate cell\n","import nest_asyncio\n","nest_asyncio.apply()\n","\n","from pyngrok import ngrok\n","import asyncio\n","\n","async def run_app():\n","    public_url = ngrok.connect(5000)\n","    print(f\" * Running on {public_url}\")\n","    \n","    from werkzeug.serving import run_simple\n","    run_simple('localhost', 5000, app)\n","\n","asyncio.get_event_loop().run_until_complete(run_app())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4889139,"sourceId":8241861,"sourceType":"datasetVersion"},{"datasetId":4889150,"sourceId":8241874,"sourceType":"datasetVersion"},{"datasetId":5584227,"sourceId":9232372,"sourceType":"datasetVersion"},{"datasetId":5584334,"sourceId":9232518,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
