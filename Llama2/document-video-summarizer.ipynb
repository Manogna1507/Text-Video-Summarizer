{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8241861,"sourceType":"datasetVersion","datasetId":4889139},{"sourceId":8241874,"sourceType":"datasetVersion","datasetId":4889150},{"sourceId":9232372,"sourceType":"datasetVersion","datasetId":5584227},{"sourceId":9232518,"sourceType":"datasetVersion","datasetId":5584334}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers langchain textract ","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:21:17.667245Z","iopub.execute_input":"2024-08-27T15:21:17.667637Z","iopub.status.idle":"2024-08-27T15:21:54.802686Z","shell.execute_reply.started":"2024-08-27T15:21:17.667597Z","shell.execute_reply":"2024-08-27T15:21:54.801593Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nCollecting langchain\n  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\nCollecting textract\n  Downloading textract-1.6.5-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nCollecting langchain-core<0.3.0,>=0.2.32 (from langchain)\n  Downloading langchain_core-0.2.35-py3-none-any.whl.metadata (6.2 kB)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.105-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nCollecting argcomplete~=1.10.0 (from textract)\n  Downloading argcomplete-1.10.3-py2.py3-none-any.whl.metadata (16 kB)\nCollecting beautifulsoup4~=4.8.0 (from textract)\n  Downloading beautifulsoup4-4.8.2-py3-none-any.whl.metadata (4.1 kB)\nCollecting chardet==3.* (from textract)\n  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\nCollecting docx2txt~=0.8 (from textract)\n  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting extract-msg<=0.29.* (from textract)\n  Downloading extract_msg-0.28.7-py2.py3-none-any.whl.metadata (7.8 kB)\nCollecting pdfminer.six==20191110 (from textract)\n  Downloading pdfminer.six-20191110-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting python-pptx~=0.6.18 (from textract)\n  Downloading python_pptx-0.6.23-py3-none-any.whl.metadata (18 kB)\nCollecting six~=1.12.0 (from textract)\n  Downloading six-1.12.0-py2.py3-none-any.whl.metadata (1.9 kB)\nCollecting SpeechRecognition~=3.8.1 (from textract)\n  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl.metadata (28 kB)\nCollecting xlrd~=1.2.0 (from textract)\n  Downloading xlrd-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (3.20.0)\nRequirement already satisfied: sortedcontainers in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: soupsieve>=1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4~=4.8.0->textract) (2.5)\nCollecting imapclient==2.1.0 (from extract-msg<=0.29.*->textract)\n  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: olefile>=0.46 in /opt/conda/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (0.47)\nCollecting tzlocal>=2.1 (from extract-msg<=0.29.*->textract)\n  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\nCollecting compressed-rtf>=1.0.6 (from extract-msg<=0.29.*->textract)\n  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ebcdic>=1.1.1 (from extract-msg<=0.29.*->textract)\n  Downloading ebcdic-1.1.1-py2.py3-none-any.whl.metadata (8.9 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\nCollecting packaging>=20.0 (from transformers)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\nRequirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (5.3.0)\nRequirement already satisfied: Pillow>=3.3.2 in /opt/conda/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (9.5.0)\nCollecting XlsxWriter>=0.5.7 (from python-pptx~=0.6.18->textract)\n  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (2.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\nDownloading langchain-0.2.14-py3-none-any.whl (997 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading textract-1.6.5-py3-none-any.whl (23 kB)\nDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\nDownloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.35-py3-none-any.whl (394 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.105-py3-none-any.whl (150 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.5/150.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading six-1.12.0-py2.py3-none-any.whl (10 kB)\nDownloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\nDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf\n  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=2d3b6fb0c528f3d6fda8d5085a6c7195b7f0bfbc23571da271b171dfd73ae044\n  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n  Building wheel for compressed-rtf (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6185 sha256=dd73d4ada5958428bd22f70dd0636b2ec912e83f15cb1ba0186d9b53683f2ccc\n  Stored in directory: /root/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\nSuccessfully built docx2txt compressed-rtf\n\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: SpeechRecognition, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, tzlocal, six, packaging, beautifulsoup4, python-pptx, pdfminer.six, imapclient, langsmith, extract-msg, textract, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: six\n    Found existing installation: six 1.16.0\n    Uninstalling six-1.16.0:\n      Successfully uninstalled six-1.16.0\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: beautifulsoup4\n    Found existing installation: beautifulsoup4 4.12.3\n    Uninstalling beautifulsoup4-4.12.3:\n      Successfully uninstalled beautifulsoup4-4.12.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.2 requires cubinlinker, which is not installed.\ncudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.2 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\npyarabic 0.6.15 requires six>=1.14.0, but you have six 1.12.0 which is incompatible.\ncudf 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.4 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.2 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nopencensus 0.11.4 requires six~=1.16, but you have six 1.12.0 which is incompatible.\nosmnx 1.9.4 requires shapely<2.1,>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntextblob 0.18.0.post0 requires nltk>=3.8, but you have nltk 3.2.4 which is incompatible.\nydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed SpeechRecognition-3.8.1 XlsxWriter-3.2.0 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 langchain-0.2.14 langchain-core-0.2.35 langchain-text-splitters-0.2.2 langsmith-0.1.105 packaging-24.1 pdfminer.six-20191110 python-pptx-0.6.23 six-1.12.0 textract-1.6.5 tzlocal-5.2 xlrd-1.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install langchain\n!pip install torch\n!pip install tensorflow\n!pip install langchain_community","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:21:54.804652Z","iopub.execute_input":"2024-08-27T15:21:54.804978Z","iopub.status.idle":"2024-08-27T15:23:03.246061Z","shell.execute_reply.started":"2024-08-27T15:21:54.804944Z","shell.execute_reply":"2024-08-27T15:23:03.244939Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.14)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.35)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.105)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (2.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mCollecting langchain_community\n  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nRequirement already satisfied: langchain<0.3.0,>=0.2.13 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.14)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.35)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.105)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (2.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.0)\nDownloading langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: langchain_community\nSuccessfully installed langchain_community-0.2.12\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Video to Text Transcribe","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/openai/whisper.git -q","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:23:03.247756Z","iopub.execute_input":"2024-08-27T15:23:03.248153Z","iopub.status.idle":"2024-08-27T15:23:37.782487Z","shell.execute_reply.started":"2024-08-27T15:23:03.248109Z","shell.execute_reply":"2024-08-27T15:23:37.781517Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:23:37.785091Z","iopub.execute_input":"2024-08-27T15:23:37.785425Z","iopub.status.idle":"2024-08-27T15:23:55.477709Z","shell.execute_reply.started":"2024-08-27T15:23:37.785391Z","shell.execute_reply":"2024-08-27T15:23:55.476580Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ndpfzbpe\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ndpfzbpe\n  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=c17a676995e00c5db6be00abb37f430ef070668a1fde719c511ec06f4178f2db\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0j6m9o5b/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\nSuccessfully built openai-whisper\nInstalling collected packages: openai-whisper\n  Attempting uninstall: openai-whisper\n    Found existing installation: openai-whisper 20231117\n    Uninstalling openai-whisper-20231117:\n      Successfully uninstalled openai-whisper-20231117\nSuccessfully installed openai-whisper-20231117\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install setuptools-rust","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:23:55.479296Z","iopub.execute_input":"2024-08-27T15:23:55.479716Z","iopub.status.idle":"2024-08-27T15:24:10.727170Z","shell.execute_reply.started":"2024-08-27T15:23:55.479670Z","shell.execute_reply":"2024-08-27T15:24:10.726040Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting setuptools-rust\n  Downloading setuptools_rust-1.10.1-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: setuptools>=62.4 in /opt/conda/lib/python3.10/site-packages (from setuptools-rust) (70.0.0)\nCollecting semantic-version<3,>=2.8.2 (from setuptools-rust)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nDownloading setuptools_rust-1.10.1-py3-none-any.whl (26 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: semantic-version, setuptools-rust\nSuccessfully installed semantic-version-2.10.0 setuptools-rust-1.10.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import whisper\n\nmodel = whisper.load_model(\"base\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:24:10.728633Z","iopub.execute_input":"2024-08-27T15:24:10.728965Z","iopub.status.idle":"2024-08-27T15:24:17.260653Z","shell.execute_reply.started":"2024-08-27T15:24:10.728931Z","shell.execute_reply":"2024-08-27T15:24:17.259729Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 192MiB/s]\n/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.device","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:24:17.262287Z","iopub.execute_input":"2024-08-27T15:24:17.263259Z","iopub.status.idle":"2024-08-27T15:24:17.270584Z","shell.execute_reply.started":"2024-08-27T15:24:17.263194Z","shell.execute_reply":"2024-08-27T15:24:17.269596Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"!pip install yt_dlp ","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:24:17.272157Z","iopub.execute_input":"2024-08-27T15:24:17.272554Z","iopub.status.idle":"2024-08-27T15:24:33.905546Z","shell.execute_reply.started":"2024-08-27T15:24:17.272495Z","shell.execute_reply":"2024-08-27T15:24:33.904427Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting yt_dlp\n  Downloading yt_dlp-2024.8.6-py3-none-any.whl.metadata (170 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.1/170.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: brotli in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (1.1.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (2024.7.4)\nCollecting mutagen (from yt_dlp)\n  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\nCollecting pycryptodomex (from yt_dlp)\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: requests<3,>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (2.32.3)\nRequirement already satisfied: urllib3<3,>=1.26.17 in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (1.26.18)\nRequirement already satisfied: websockets>=12.0 in /opt/conda/lib/python3.10/site-packages (from yt_dlp) (12.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.32.2->yt_dlp) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.32.2->yt_dlp) (3.7)\nDownloading yt_dlp-2024.8.6-py3-none-any.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: pycryptodomex, mutagen, yt_dlp\nSuccessfully installed mutagen-1.47.0 pycryptodomex-3.20.0 yt_dlp-2024.8.6\n","output_type":"stream"}]},{"cell_type":"code","source":"import yt_dlp\n\ndef extract_audio(url):\n    \"\"\"Extracts audio from a YouTube video using yt-dlp.\"\"\"\n    ydl_opts = {\n        'format': 'bestaudio/best',\n        'postprocessors': [{\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': 'mp3',\n            'preferredquality': '192',\n        }],\n        'outtmpl': 'output.%(ext)s'\n    }\n\n    try:\n        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n            info_dict = ydl.extract_info(url, download=True)\n            audio_file = ydl.prepare_filename(info_dict)\n            audio_file = audio_file.replace('.webm', '.mp3')  # Ensure correct file extension\n            return audio_file\n    except Exception as e:\n        print(f\"Error extracting audio: {e}\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:24:33.907048Z","iopub.execute_input":"2024-08-27T15:24:33.907477Z","iopub.status.idle":"2024-08-27T15:24:34.535048Z","shell.execute_reply.started":"2024-08-27T15:24:33.907411Z","shell.execute_reply":"2024-08-27T15:24:34.534007Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"url = \"https://www.youtube.com/watch?v=VO9q66JEdVk\"\nextract_audio(url)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:24:34.538857Z","iopub.execute_input":"2024-08-27T15:24:34.539168Z","iopub.status.idle":"2024-08-27T15:24:58.179703Z","shell.execute_reply.started":"2024-08-27T15:24:34.539135Z","shell.execute_reply":"2024-08-27T15:24:58.178743Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[youtube] Extracting URL: https://www.youtube.com/watch?v=VO9q66JEdVk\n[youtube] VO9q66JEdVk: Downloading webpage\n[youtube] VO9q66JEdVk: Downloading ios player API JSON\n[youtube] VO9q66JEdVk: Downloading web creator player API JSON\n[youtube] VO9q66JEdVk: Downloading player 19828c26\n[youtube] VO9q66JEdVk: Downloading m3u8 information\n[info] VO9q66JEdVk: Downloading 1 format(s): 251\n[download] Destination: output.webm\n[download] 100% of    5.81MiB in 00:00:00 at 12.92MiB/s  \n[ExtractAudio] Destination: output.mp3\nDeleting original file output.webm (pass -k to keep)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'output.mp3'"},"metadata":{}}]},{"cell_type":"code","source":"def transcribe_audio(file_path):\n    \"\"\"Transcribes audio to text using the Whisper model.\"\"\"\n    try:\n        model = whisper.load_model('base')\n        result = model.transcribe(file_path)\n        return result['text']\n    except Exception as e:\n        print(f\"Error transcribing audio: {e}\")\n        return None\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:24:58.180815Z","iopub.execute_input":"2024-08-27T15:24:58.181125Z","iopub.status.idle":"2024-08-27T15:24:58.186438Z","shell.execute_reply.started":"2024-08-27T15:24:58.181092Z","shell.execute_reply":"2024-08-27T15:24:58.185551Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"text = transcribe_audio(\"/kaggle/working/output.mp3\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:24:58.187508Z","iopub.execute_input":"2024-08-27T15:24:58.187852Z","iopub.status.idle":"2024-08-27T15:25:19.504304Z","shell.execute_reply.started":"2024-08-27T15:24:58.187817Z","shell.execute_reply":"2024-08-27T15:25:19.503265Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"}]},{"cell_type":"code","source":"text","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:25:19.505942Z","iopub.execute_input":"2024-08-27T15:25:19.506253Z","iopub.status.idle":"2024-08-27T15:25:19.512504Z","shell.execute_reply.started":"2024-08-27T15:25:19.506221Z","shell.execute_reply":"2024-08-27T15:25:19.511493Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"\" Hi everyone, I'm Monar Aganti. Today I'm going to introduce you to a text and video summarization app. So in this video, I'll walk you through the app's features, architecture, typical use cases and also potential upgrades. So let's get started. First, let's talk about what this presentation will cover. Will outline our text and video summarization app, explore its architecture, go through some typical use cases and discuss potential future upgrades. And our goal is to show you how this innovative solution can make your life easier and more productive. Now let's talk about the overview of the app. Our app helps users putly grasp the events of documents, videos and articles. So it uses cutting edge technology to generate concise summaries and also highlighting key information for efficient learning or information retrieval. The key features are of our app, include the ability to summarize various text formats like documents, blog posts and video transcripts. Additionally, the app also monitors YouTube channels and automatically generates summaries for newly uploaded videos, which are the delivery to users through question notifications. Now let's walk through the user interface of our app. As you can see, there are four slides presented here starting with slide one. We have the sign up screen. So to start with the app, you need to sign up by entering your email and password. But if you already have an account and login direction and in the second slide, login by using your email and password directly. In the third slide, we have the main menu of the app, which is text and video summarization buttons. So let's say we see the text input screen. Now take an example paragraph about pollution and you type that into input box and hit send. And you will get a summarized text. As for a video, you can simply paste the URL by IC and the app will provide a concise summary of the video content. So that's the user interface of our app. Now let's talk about the architecture diagram of our app. As you can see, the diagram shows the flow chart of data and process in the app, which starts from user input and end and with delivery of some ways to use it. So here's a detailed breakdown of each component and how they interact. It starts with user input. The user begins by providing content to the app. So this could be in the form of text images of videos. And the apps suddenly interface, which is flutter allows user to easily upload or keep their content. Then comes the flood up front end. So if the user provides text or document input, then the app immediately sends this data to the summarization engine via an apr request. And as for video URLs, the app uses the YouTube API to fetch videos transcript. So the app continuously monitors last specified YouTube channels for new videos. So when a new videos uploaded, the app detects it and fetches the relevant details and transcripts using YouTube API. So once the content is ready, the app sends an apr request to the summarization engine, which is llama to. So llama to receives that the text or video transcript using advanced natural language, courses and techniques. It analyzes the content and extracts key points to generate a concise summary. So this summarization engine produces summary that highlights the most important information from the input content. Now let's talk about the summary handling. The generated summary is sent back to the flutter front end. The app displays the summary in a user friendly format, which makes it easier for the user to read and understand. But also the summary is also sent to fire this for storage, because this allows the app to keep a record of all the summaries generated for the user. And as for the flutter back end, the fire base securely store the summaries and also the user data like they emails and etc. So this ensures that the users can action their summaries at any time and that they de-tie protected. And as for the push notifications, fire with cloud messaging sends push notifications to the user device, which keeps users informed about new summaries without needing to open the app. Now let's talk in detail about the user notification when you enter a YouTube URL into the app for summarization. It stores the URL. Then the app follows the YouTube channel related to that URL. So whenever new videos are uploaded to that channel, the app makes a new summary and then the user receives a push notification. And this notification provides a quick alert that new content is available. Now if you want to access that summary, you can directly open the app to read that summary. This ensures that they see updated with minimum of 40. So this is the complete architecture diagram of our app. Now let's talk about physical use cases of our summarization app. There are many uses for this app, but let's discuss a few typical cases. Let's start with exam preparation. The students can easily upload their text materials like study materials. Let's lecture no, also text tricks. Then our app generates summaries to help them review quickly, which is useful for exams. This way they can study efficiency and also retain more information for their exams. As for the interview highlights, especially for jobs you see us. The app is a game changer by inputting links to interviews or documentaries. Users can extract and summarize key insights. This provides a valuable resource for preparing for interviews or conductive research, which makes the job search a bit easier. Now staying updated is crucial and our app helps with that. Users can monitor their favorite YouTube channels like for new content. And the app automatically summarizes new uploads and sends notifications, which enables the users to keep learning and stay informed about the latest terms. As for the potential updates, we'll see what else can we add to the app. In hands and AI models, we are looking to integrate advanced summarization models, which enhance the accuracy and relevance of our summaries. Which will deliver a more new sense done informative experience for our users. And also to broaden our appeal, we can expand the app to support multiple languages. This will make it accessible to users around the group reaching a much wider audience. And to improve the performance of the app, we can implement feedback mechanisms here. The users can refine the summaries to better fit their needs. Like this will personalize their experience and also significantly enhance their overall satisfaction. As for the offline mode, it convenience significantly. So we are we can enable the offline access to download summaries. This will allow users to access the material anytime, even without an internet connection. So this is the overview of the text summarization app so far. I hope it helps you and thank you for watching.\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Document Summarization Using Bart","metadata":{}},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:25:19.513645Z","iopub.execute_input":"2024-08-27T15:25:19.513982Z","iopub.status.idle":"2024-08-27T15:25:21.714040Z","shell.execute_reply.started":"2024-08-27T15:25:19.513949Z","shell.execute_reply":"2024-08-27T15:25:21.713211Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = BartForConditionalGeneration.from_pretrained(\n        'facebook/bart-large-cnn')\n\ntokenizer = BartTokenizer.from_pretrained(\n            'facebook/bart-large-cnn')","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:25:21.715310Z","iopub.execute_input":"2024-08-27T15:25:21.715880Z","iopub.status.idle":"2024-08-27T15:25:30.049411Z","shell.execute_reply.started":"2024-08-27T15:25:21.715835Z","shell.execute_reply":"2024-08-27T15:25:30.048465Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b738fada1d47470cbff41d8434070c6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa779a83b564499498e100c855fcda70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16dde91761b4e729e30b76170693ed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b375e694b7f0449cbf4fdfa2bc272209"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fe4e4c1605841039b8577d5524d86bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8817625e6184031b2ac7b54c88531d3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import textract\n\ndef extract_text(file_path):\n    try:\n        text = textract.process(file_path)\n        return text.decode('utf-8')\n    except Exception as e:\n        print(f\"An error occurred while processing {file_path}: {e}\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:25:30.050768Z","iopub.execute_input":"2024-08-27T15:25:30.051086Z","iopub.status.idle":"2024-08-27T15:25:30.058231Z","shell.execute_reply.started":"2024-08-27T15:25:30.051053Z","shell.execute_reply":"2024-08-27T15:25:30.057324Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def summarize(text, maxSummarylength):\n    # Encode the text and summarize\n    inputs = tokenizer.encode(\"summarize: \" +\n                              text,\n                              return_tensors = \"pt\",\n                              max_length = 1024, truncation=True)\n\n    summary_ids = model.generate(inputs,\n                                 max_length = maxSummarylength,\n                                 min_length = int(maxSummarylength/5),\n                                 length_penalty = 10.0,\n                                 num_beams = 4,\n                                 early_stopping = True)\n\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens = True)\n\n    return summary","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:25:30.059520Z","iopub.execute_input":"2024-08-27T15:25:30.059968Z","iopub.status.idle":"2024-08-27T15:25:30.072963Z","shell.execute_reply.started":"2024-08-27T15:25:30.059925Z","shell.execute_reply":"2024-08-27T15:25:30.071989Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"def split_text_into_pieces(text, max_tokens=1024, use_sentence_boundary=False):\n    \"\"\"\n    Splits the text into pieces based on the max_tokens, optionally considering sentence boundaries.\n    \n    Parameters:\n    text (str): The text to be split.\n    max_tokens (int): Maximum tokens per piece.\n    use_sentence_boundary (bool): Whether to split at sentence boundaries.\n    \n    Returns:\n    List[str]: A list of text pieces.\n    \"\"\"\n    if use_sentence_boundary:\n        sentences = text.split('. ')\n        pieces = []\n        current_piece = ''\n        for sentence in sentences:\n            if len(tokenizer.tokenize(current_piece + sentence)) <= max_tokens:\n                current_piece += sentence + '. '\n            else:\n                pieces.append(current_piece.strip())\n                current_piece = sentence + '. '\n        if current_piece:\n            pieces.append(current_piece.strip())\n        return pieces\n    else:\n        return [text[i:i+max_tokens] for i in range(0, len(text), max_tokens)]","metadata":{"execution":{"iopub.status.busy":"2024-08-27T07:59:20.888871Z","iopub.execute_input":"2024-08-27T07:59:20.889287Z","iopub.status.idle":"2024-08-27T07:59:20.896844Z","shell.execute_reply.started":"2024-08-27T07:59:20.889249Z","shell.execute_reply":"2024-08-27T07:59:20.895851Z"}}},{"cell_type":"markdown","source":"def recursive_summarize(text, max_length=1024, recursion_level=0, detail_level=3):\n    \"\"\"\n    Recursive summarization function that provides a concise yet detailed summary.\n    \n    Parameters:\n    text (str): The text to be summarized.\n    max_length (int): The maximum token length for each chunk.\n    recursion_level (int): Current recursion level (used internally for tracking depth).\n    detail_level (int): Level of detail for the final summary. Lower values produce more detailed summaries.\n    \n    Returns:\n    str: The final summary after recursive summarization.\n    \"\"\"\n    recursion_level += 1\n    print(\"######### Recursion level: \", recursion_level, \"\\n\\n######### \")\n\n    tokens = tokenizer.tokenize(text)\n    expected_count_of_chunks = len(tokens) / max_length\n    max_length = int(len(tokens) / expected_count_of_chunks) + 2\n\n    # Break the text into pieces based on max_length, considering sentence boundaries\n    pieces = split_text_into_pieces(text, max_tokens=max_length, use_sentence_boundary=True)\n\n    print(\"Number of pieces: \", len(pieces))\n\n    # Summarize each piece\n    summaries = []\n    for k, piece in enumerate(pieces):\n        print(\"****************************************************\")\n        print(\"Piece:\", k + 1, \" out of \", len(pieces), \"pieces\")\n        print(piece, \"\\n\")\n        \n        # Adjust summary length based on detail level\n        summary_length = int(max_length / detail_level)\n        summary = summarize(piece, maxSummarylength=summary_length)\n        \n        print(\"SUMMARY: \", summary)\n        summaries.append(summary)\n        print(\"****************************************************\")\n\n    # Concatenate the summaries and tokenize again\n    concatenated_summary = ' '.join(summaries)\n    tokens = tokenizer.tokenize(concatenated_summary)\n\n    if len(tokens) > max_length:\n        # If the concatenated summary is too long, repeat the process\n        print(\"############# GOING RECURSIVE ##############\")\n        return recursive_summarize(concatenated_summary,\n                                   max_length=max_length,\n                                   recursion_level=recursion_level,\n                                   detail_level=detail_level)\n    else:\n        # Perform a final summarization if necessary\n        final_summary = concatenated_summary\n        if len(pieces) > 1:\n            final_summary = summarize(concatenated_summary,\n                                      maxSummarylength=int(max_length / detail_level * 2))\n\n        return final_summary\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:16:19.710201Z","iopub.execute_input":"2024-08-27T08:16:19.711404Z","iopub.status.idle":"2024-08-27T08:16:19.724050Z","shell.execute_reply.started":"2024-08-27T08:16:19.711318Z","shell.execute_reply":"2024-08-27T08:16:19.722667Z"}}},{"cell_type":"code","source":"def split_text_into_pieces(text, max_tokens=1024, use_sentence_boundary=False):\n    \"\"\"\n    Splits the text into pieces based on the max_tokens, optionally considering sentence boundaries.\n    \n    Parameters:\n    text (str): The text to be split.\n    max_tokens (int): Maximum tokens per piece.\n    use_sentence_boundary (bool): Whether to split at sentence boundaries.\n    \n    Returns:\n    List[str]: A list of text pieces.\n    \"\"\"\n    if use_sentence_boundary:\n        sentences = text.split('. ')\n        pieces = []\n        current_piece = ''\n        for sentence in sentences:\n            if len(tokenizer.tokenize(current_piece + sentence)) <= max_tokens:\n                current_piece += sentence + '. '\n            else:\n                pieces.append(current_piece.strip())\n                current_piece = sentence + '. '\n        if current_piece:\n            pieces.append(current_piece.strip())\n        return pieces\n    else:\n        return [text[i:i+max_tokens] for i in range(0, len(text), max_tokens)]","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:25:30.074129Z","iopub.execute_input":"2024-08-27T15:25:30.074420Z","iopub.status.idle":"2024-08-27T15:25:30.084963Z","shell.execute_reply.started":"2024-08-27T15:25:30.074389Z","shell.execute_reply":"2024-08-27T15:25:30.084167Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def recursive_summarize(text, max_length=1024, recursion_level=0, detail_level=3):\n    \"\"\"\n    Recursive summarization function that provides a concise yet detailed summary.\n    \n    Parameters:\n    text (str): The text to be summarized.\n    max_length (int): The maximum token length for each chunk.\n    recursion_level (int): Current recursion level (used internally for tracking depth).\n    detail_level (int): Level of detail for the final summary. Lower values produce more detailed summaries.\n    \n    Returns:\n    str: The final summary after recursive summarization.\n    \"\"\"\n    recursion_level += 1\n\n    tokens = tokenizer.tokenize(text)\n    expected_count_of_chunks = len(tokens) / max_length\n    max_length = int(len(tokens) / expected_count_of_chunks) + 2\n\n    # Break the text into pieces based on max_length, considering sentence boundaries\n    pieces = split_text_into_pieces(text, max_tokens=max_length, use_sentence_boundary=True)\n\n    # Summarize each piece\n    summaries = []\n    for piece in pieces:\n        # Adjust summary length based on detail level\n        summary_length = int(max_length / detail_level)\n        summary = summarize(piece, summary_length)\n        summaries.append(summary)\n\n    # Concatenate the summaries and tokenize again\n    concatenated_summary = ' '.join(summaries)\n    tokens = tokenizer.tokenize(concatenated_summary)\n\n    if len(tokens) > max_length:\n        # If the concatenated summary is too long, repeat the process\n        return recursive_summarize(concatenated_summary,\n                                   max_length=max_length,\n                                   recursion_level=recursion_level,\n                                   detail_level=detail_level)\n    else:\n        # Perform a final summarization if necessary\n        final_summary = concatenated_summary\n        if len(pieces) > 1:\n            final_summary = summarize(concatenated_summary,\n                                      maxSummarylength=int(max_length / detail_level * 2))\n\n        return final_summary","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:25:30.086101Z","iopub.execute_input":"2024-08-27T15:25:30.086438Z","iopub.status.idle":"2024-08-27T15:25:30.100934Z","shell.execute_reply.started":"2024-08-27T15:25:30.086406Z","shell.execute_reply":"2024-08-27T15:25:30.100098Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"document = extract_text(\"/kaggle/input/dbms-da/DBMS Unit 5 Tesseract.pdf\")\n\nif document:\n    summary = recursive_summarize(document, max_length=1024, detail_level=3)\n    print(\"Concise and Detailed Summary:\")\n    print(summary)\nelse:\n    print(\"Failed to extract text from the document.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:25:30.102017Z","iopub.execute_input":"2024-08-27T15:25:30.102342Z","iopub.status.idle":"2024-08-27T15:28:01.777405Z","shell.execute_reply.started":"2024-08-27T15:25:30.102306Z","shell.execute_reply":"2024-08-27T15:28:01.776363Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Concise and Detailed Summary:\nA trigger is a stored database object that is automatically executed or fired on a DML command. A procedure is a subroutine or a subprogram in the language of the database. Triggers are used to invoke procedures by using other triggers, such as Java, Python, PHP, etc. The Data Controlling Language (DCL) helps users to retrieve, modify and delete data stored on the server. DCL commands can be used to grant or revoke user permissions and privileges as per the administrator’s needs. The DBA is the focal point for data/user interaction in an organization. The technical aspects of the DBA's job are rooted in the following areas of operation: design, development, implementation, and maintenance.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Flask Backend Using Ngrok","metadata":{}},{"cell_type":"code","source":"!pip install pyngrok flask_ngrok","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:28:01.778952Z","iopub.execute_input":"2024-08-27T15:28:01.779739Z","iopub.status.idle":"2024-08-27T15:28:15.299034Z","shell.execute_reply.started":"2024-08-27T15:28:01.779682Z","shell.execute_reply":"2024-08-27T15:28:15.297912Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Collecting pyngrok\n  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\nCollecting flask_ngrok\n  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\nRequirement already satisfied: Flask>=0.8 in /opt/conda/lib/python3.10/site-packages (from flask_ngrok) (3.0.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from flask_ngrok) (2.32.3)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (3.0.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask_ngrok) (1.8.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->flask_ngrok) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->flask_ngrok) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->flask_ngrok) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->flask_ngrok) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask>=0.8->flask_ngrok) (2.1.5)\nDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\nDownloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: pyngrok, flask_ngrok\nSuccessfully installed flask_ngrok-0.0.25 pyngrok-7.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install flask_cors","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:28:15.300634Z","iopub.execute_input":"2024-08-27T15:28:15.301058Z","iopub.status.idle":"2024-08-27T15:28:28.500052Z","shell.execute_reply.started":"2024-08-27T15:28:15.301007Z","shell.execute_reply":"2024-08-27T15:28:28.498889Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Collecting flask_cors\n  Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: Flask>=0.9 in /opt/conda/lib/python3.10/site-packages (from flask_cors) (3.0.3)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (3.0.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.9->flask_cors) (1.8.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask_cors) (2.1.5)\nDownloading Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: flask_cors\nSuccessfully installed flask_cors-4.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!ngrok authtoken \"2hV5aDFehrlTUWWsBnwsDfEb8AZ_5LZnWqSeSurLptmYbZHb4\"","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:28:28.501503Z","iopub.execute_input":"2024-08-27T15:28:28.501864Z","iopub.status.idle":"2024-08-27T15:28:30.802163Z","shell.execute_reply.started":"2024-08-27T15:28:28.501829Z","shell.execute_reply":"2024-08-27T15:28:30.800977Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \n","output_type":"stream"}]},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Connect to the local Flask server running on port 5000\npublic_url = ngrok.connect(addr=\"5000\")\nprint('* ngrok tunnel \"{}\" -> \"http://127.0.0.1:5000\"'.format(public_url))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:28:30.803725Z","iopub.execute_input":"2024-08-27T15:28:30.804066Z","iopub.status.idle":"2024-08-27T15:28:31.180870Z","shell.execute_reply.started":"2024-08-27T15:28:30.804031Z","shell.execute_reply":"2024-08-27T15:28:31.179818Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"* ngrok tunnel \"NgrokTunnel: \"https://5e84-34-83-231-88.ngrok-free.app\" -> \"http://localhost:5000\"\" -> \"http://127.0.0.1:5000\"\n","output_type":"stream"}]},{"cell_type":"code","source":"%mkdir templates -p","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:28:31.182200Z","iopub.execute_input":"2024-08-27T15:28:31.183009Z","iopub.status.idle":"2024-08-27T15:28:32.237557Z","shell.execute_reply.started":"2024-08-27T15:28:31.182961Z","shell.execute_reply":"2024-08-27T15:28:32.236269Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"%%writefile templates/index.html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document Summarizer</title>\n</head>\n<body>\n    <h1>Document Summarizer</h1>\n    <form action=\"/\" method=\"POST\" enctype=\"multipart/form-data\">\n        <label for=\"file\">Upload a file:</label><br>\n        <input type=\"file\" id=\"file\" name=\"file\"><br><br>\n        \n        <label for=\"youtube_url\">Or enter a YouTube URL:</label><br>\n        <input type=\"url\" id=\"youtube_url\" name=\"youtube_url\" placeholder=\"https://www.youtube.com/watch?v=...\"><br><br>\n\n        <input type=\"submit\" value=\"Summarize\">\n    </form>\n    \n    {% if summary_text %}\n    <h2>Summary:</h2>\n    <textarea id=\"summary_text\" rows=\"10\" cols=\"80\">{{ summary_text }}</textarea><br><br>\n    <p>Generation Time: {{ generation_time }} seconds</p>\n    {% else %}\n    <p>No summary generated yet.</p>\n    {% endif %}\n</body>\n</html>\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:28:32.239413Z","iopub.execute_input":"2024-08-27T15:28:32.240121Z","iopub.status.idle":"2024-08-27T15:28:32.248897Z","shell.execute_reply.started":"2024-08-27T15:28:32.240081Z","shell.execute_reply":"2024-08-27T15:28:32.247523Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Writing templates/index.html\n","output_type":"stream"}]},{"cell_type":"code","source":"from flask import Flask, request, jsonify\nfrom flask_cors import CORS\nimport os\nimport time\nfrom werkzeug.utils import secure_filename\nfrom pyngrok import ngrok\nimport textract  # Make sure to import textract\n\napp = Flask(__name__)\nCORS(app, resources={r\"/*\": {\"origins\": \"*\"}}, supports_credentials=True)\n\n# Allowed file extensions\nALLOWED_EXTENSIONS = {'pdf', 'docx', 'txt'}\n\ndef allowed_file(filename):\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n\ndef get_summary(text):\n    try:\n        start_time = time.time()\n        summary = recursive_summarize(text, max_length=1024, detail_level=3)\n        end_time = time.time()\n        generation_time = round(end_time - start_time, 2)\n        return summary, generation_time\n    except Exception as e:\n        return f\"An error occurred: {str(e)}\", 0\n\n@app.route('/summarize', methods=['POST'])\ndef summarize_route():\n    input_text = None\n    youtube_url = request.form.get('youtube_url', '')\n\n    # Debug logs\n    print(\"Request received\")\n    print(f\"YouTube URL: {youtube_url}\")\n\n    if 'file' in request.files and request.files['file'].filename != '':\n        file = request.files['file']\n        if file and allowed_file(file.filename):\n            filename = secure_filename(file.filename)\n            file_path = os.path.join(app.root_path, filename)\n            file.save(file_path)\n            input_text = textract.process(file_path).decode('utf-8')\n            os.remove(file_path)\n            print(f\"File processed: {filename}\")\n        else:\n            print(\"Invalid file type or no file selected.\")\n    elif youtube_url:\n        audio_file = extract_audio(youtube_url)\n        if audio_file:\n            input_text = transcribe_audio(audio_file)\n            os.remove(audio_file)\n            print(\"YouTube audio processed.\")\n        else:\n            print(\"Failed to extract audio.\")\n    \n    if input_text:\n        summary, generation_time = get_summary(input_text)\n        return jsonify({\n            'summary_text': summary,\n            'generation_time': generation_time\n        })\n    else:\n        return jsonify({'error': 'Failed to process input.'}), 400\n\n# Note: We're not running the app here","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:39:09.840753Z","iopub.execute_input":"2024-08-27T15:39:09.841177Z","iopub.status.idle":"2024-08-27T15:39:09.857159Z","shell.execute_reply.started":"2024-08-27T15:39:09.841138Z","shell.execute_reply":"2024-08-27T15:39:09.856179Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Run this in a separate cell\nimport nest_asyncio\nnest_asyncio.apply()\n\nfrom pyngrok import ngrok\nimport asyncio\n\nasync def run_app():\n    public_url = ngrok.connect(5000)\n    print(f\" * Running on {public_url}\")\n    \n    from werkzeug.serving import run_simple\n    run_simple('localhost', 5000, app)\n\nasyncio.get_event_loop().run_until_complete(run_app())","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:57:35.773420Z","iopub.execute_input":"2024-08-27T15:57:35.773826Z","iopub.status.idle":"2024-08-27T16:03:24.632656Z","shell.execute_reply.started":"2024-08-27T15:57:35.773788Z","shell.execute_reply":"2024-08-27T16:03:24.631103Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":" * Running on NgrokTunnel: \"https://c873-34-83-231-88.ngrok-free.app\" -> \"http://localhost:5000\"\nRequest received\nYouTube URL: https://www.youtube.com/watch?v=1bUy-1hGZpI\n[youtube] Extracting URL: https://www.youtube.com/watch?v=1bUy-1hGZpI\n[youtube] 1bUy-1hGZpI: Downloading webpage\n[youtube] 1bUy-1hGZpI: Downloading ios player API JSON\n[youtube] 1bUy-1hGZpI: Downloading web creator player API JSON\n[youtube] 1bUy-1hGZpI: Downloading m3u8 information\n[info] 1bUy-1hGZpI: Downloading 1 format(s): 251\n[download] Destination: output.webm\n[download] 100% of    6.19MiB in 00:00:00 at 6.78MiB/s   \n[ExtractAudio] Destination: output.mp3\nDeleting original file output.webm (pass -k to keep)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"YouTube audio processed.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}